{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_07_yolo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xJ1xlEi5lpVW"},"source":["# video"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHmbgzcBiVru","executionInfo":{"status":"ok","timestamp":1638411667293,"user_tz":-540,"elapsed":21389,"user":{"displayName":"JINYOUNG KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16944369447100524964"}},"outputId":"8e1ff8e0-e610-4b00-b6ed-264adf673cbd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"-b9paYEL0Lmt","executionInfo":{"status":"ok","timestamp":1638411669361,"user_tz":-540,"elapsed":2071,"user":{"displayName":"JINYOUNG KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16944369447100524964"}}},"source":["import cv2\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import time\n","\n","IMAGE = '/content/drive/MyDrive/최종프로젝트/자료/공사현장.mp4'\n","CONFIG = '/content/drive/MyDrive/최종프로젝트/자료/final/yolov3_testing.cfg'\n","CLASSES = '/content/drive/MyDrive/최종프로젝트/자료/final/obj.names'\n","WEIGHTS = '/content/drive/MyDrive/최종프로젝트/자료/final/yolov3_training_5classes.weights'\n","\n","# read class names from text file\n","classes = None\n","with open(CLASSES, 'r') as f:\n","     classes = [line.strip() for line in f.readlines()]\n","        \n","scale = 0.00392\n","conf_threshold = 0.5\n","nms_threshold = 0.4\n","\n","# generate different colors for different classes \n","COLORS = np.random.uniform(0, 255, size=(len(classes), 3))"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7l22zQce3BU","executionInfo":{"status":"ok","timestamp":1638411672481,"user_tz":-540,"elapsed":524,"user":{"displayName":"JINYOUNG KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16944369447100524964"}},"outputId":"e42ca683-76da-4bff-d22c-a91ff112eca7"},"source":["print(os.path.exists(CLASSES))\n","print(os.path.exists(CONFIG))\n","print(os.path.exists(WEIGHTS))\n","print(os.path.exists(IMAGE))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","True\n","True\n"]}]},{"cell_type":"code","metadata":{"id":"b3FdNUHItA5_","executionInfo":{"status":"ok","timestamp":1638411673816,"user_tz":-540,"elapsed":3,"user":{"displayName":"JINYOUNG KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16944369447100524964"}}},"source":["# function to get the output layer names \n","# in the architecture\n","def get_output_layers(net): \n","    layer_names = net.getLayerNames()\n","    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","    return output_layers\n","\n","# function to draw bounding box on the detected object with class name\n","def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n","    label = str(classes[class_id])\n","    color = COLORS[class_id]\n","    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n","    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"id":"EX55tGQctBgo","outputId":"82811137-4a7f-4762-acdf-4406358402ef"},"source":["def processImage(image,index):\n","\n","    Width = image.shape[1]\n","    Height = image.shape[0]\n","\n","    # read pre-trained model and config file\n","    net = cv2.dnn.readNet(WEIGHTS, CONFIG)\n","\n","    # create input blob \n","    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n","    # set input blob for the network\n","    net.setInput(blob)\n","\n","    # run inference through the network\n","    # and gather predictions from output layers\n","    outs = net.forward(get_output_layers(net))\n","\n","    # initialization\n","    class_ids = []\n","    confidences = []\n","    boxes = []\n","    # for each detetion from each output layer \n","    # get the confidence, class id, bounding box params\n","    # and ignore weak detections (confidence < 0.5)\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.5:\n","                center_x = int(detection[0] * Width)\n","                center_y = int(detection[1] * Height)\n","                w = int(detection[2] * Width)\n","                h = int(detection[3] * Height)\n","                x = center_x - w / 2\n","                y = center_y - h / 2\n","                class_ids.append(class_id)\n","                confidences.append(float(confidence))\n","                boxes.append([x, y, w, h])\n","            \n","    # apply non-max suppression\n","    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n","\n","    # go through the detections remaining\n","    # after nms and draw bounding box\n","    for i in indices:\n","        i = i[0]\n","        box = boxes[i]\n","        x = box[0]\n","        y = box[1]\n","        w = box[2]\n","        h = box[3]\n","    \n","        draw_bounding_box(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n","    \n","    # display output image    \n","    out_image_name = \"object detection\"+str(index)\n","    #cv2.imshow(out_image_name, image)\n","    # wait until any key is pressed\n","    #cv2.waitKey()\n","     # save output image to disk\n","    cv2.imwrite(\"/content/drive/MyDrive/최종프로젝트/자료/결과\"+out_image_name+\".jpg\", image)\n","\n","# open the video file\n","\n","cap = cv2.VideoCapture(IMAGE)\n","print(cap)\n","prev = 10\n","frame_rate = 0.1\n","index = 0\n","\n","while (cap.isOpened()):\n","  time_elapsed = time.time() - prev\n","  ret, frame = cap.read()\n","  if time_elapsed > 1./frame_rate:\n","    prev = time.time()\n","    processImage(frame, index)\n","    index = index + 1\n","\n","# release resources\n","cv2.destroyAllWindows()\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<VideoCapture 0x7f84b94cf8d0>\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-c2d5b4657ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mframe_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mprocessImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-c2d5b4657ef6>\u001b[0m in \u001b[0;36mprocessImage\u001b[0;34m(image, index)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocessImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mWidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}]},{"cell_type":"code","metadata":{"id":"v7yjJxmCS44Y"},"source":["import cv2\n"," \n","cap = cv2.VideoCapture(0)\n","width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","print('original size: %d, %d' % (width, height))\n"," \n","cap.set(cv2.CAP_PROP_FRAME_WIDTH, width/3)\n","cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height/3)\n"," \n","width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","print('changed size: %d, %d' % (width, height))\n","\n","\n","출처: https://hyongdoc.tistory.com/348 [Doony Garage]"],"execution_count":null,"outputs":[]}]}